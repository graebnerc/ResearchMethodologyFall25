{
  "hash": "d2c6a27b38057f46551c77c25394e0a3",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Implementation Lab: Linear Regression & Experimental Analysis\"\nsubtitle: \"90-Minute Session Guide\"\nauthor: \"Instructor Guide\"\nformat:\n  html:\n    toc: true\n    toc-depth: 3\n    code-fold: show\n    code-tools: true\n    theme: cosmo\n  pdf:\n    toc: true\n    number-sections: true\n    geometry: margin=2cm\n---\n\n# Lab Overview\n\n**Duration:** 90 minutes  \n**Format:** Live coding demonstration + guided exercise  \n**Datasets:** All created via simulation code below\n\n## Learning Objectives\n\nBy the end of this lab, students will be able to:\n\n- Implement simple and multiple linear regression in R\n- Understand omitted variable bias through practical examples\n- Perform log transformations for exponential relationships\n- Conduct t-tests and ANOVA for experimental data\n- Calculate and interpret effect sizes\n- Check key statistical assumptions\n\n## Session Structure\n\n| Time | Section | Duration |\n|------|---------|----------|\n| 0:00-0:05 | Introduction & Setup | 5 min |\n| 0:05-0:35 | Linear Regression | 30 min |\n| 0:35-0:70 | Experimental Analysis | 35 min |\n| 0:70-0:90 | Guided Exercise | 20 min |\n\n---\n\n# Preparation: Data Generation\n\n**Run this code before the lab to create all datasets.**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load required packages\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(broom)\nlibrary(effectsize)\nlibrary(car)\n\n# Set seed for reproducibility\nset.seed(42)\n```\n:::\n\n\n## Dataset 1: Marketing Data (Regression)\n\n**Purpose:** Demonstrate simple vs. multiple regression and omitted variable bias\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Generate marketing dataset\nn <- 100\nad_spend <- runif(n, 10, 100)\nwebsite_traffic <- 50 + 0.8 * ad_spend + rnorm(n, 0, 10)\nsales_revenue <- 20 + 2.2 * ad_spend + 1.0 * website_traffic + rnorm(n, 0, 15)\n\nmarketing_data <- data.frame(\n  ad_spend = ad_spend,\n  website_traffic = website_traffic,\n  sales_revenue = sales_revenue\n)\n\n# Save for students\nwrite.csv(marketing_data, \"marketing_data.csv\", row.names = FALSE)\n\nhead(marketing_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  ad_spend website_traffic sales_revenue\n1 92.33254       127.08529      349.6064\n2 94.33679       117.63104      321.8988\n3 35.75256        94.35932      210.5225\n4 84.74029       124.22122      326.5452\n5 67.75710       105.10328      267.1512\n6 56.71864        98.14042      224.3476\n```\n\n\n:::\n:::\n\n\n## Dataset 2: Firm Growth (Log Transformation)\n\n**Purpose:** Demonstrate exponential growth and log transformation\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Generate exponential growth data\nyears <- 1:20\nrevenue <- 50000 * exp(0.12 * years) + rnorm(20, 0, 20000)\n\nfirm_growth_data <- data.frame(\n  year = years,\n  revenue = revenue\n)\n\n# Save for students\nwrite.csv(firm_growth_data, \"firm_growth_data.csv\", row.names = FALSE)\n\nhead(firm_growth_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  year   revenue\n1    1  34451.72\n2    2  64543.47\n3    3  47696.55\n4    4  84604.10\n5    5 117060.06\n6    6  82044.19\n```\n\n\n:::\n:::\n\n\n## Dataset 3: Leadership Training (t-test)\n\n**Purpose:** Demonstrate independent samples t-test\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Generate between-subjects leadership data\nn_per_group <- 30\n\nleadership_study_between <- data.frame(\n  participant_id = 1:(2 * n_per_group),\n  group = rep(c(\"control\", \"training\"), each = n_per_group),\n  team_performance = c(\n    rnorm(n_per_group, mean = 75, sd = 9),  # control\n    rnorm(n_per_group, mean = 84, sd = 9)   # training\n  )\n)\n\n# Save for students\nwrite.csv(leadership_study_between, \"leadership_study_between.csv\", row.names = FALSE)\n\nhead(leadership_study_between)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  participant_id   group team_performance\n1              1 control         80.16377\n2              2 control         75.41223\n3              3 control         76.41671\n4              4 control         78.88409\n5              5 control         71.43105\n6              6 control         86.78980\n```\n\n\n:::\n:::\n\n\n## Dataset 4: Communication Study (ANOVA)\n\n**Purpose:** Demonstrate one-way ANOVA with three groups\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Generate communication study data with 3 groups\nn_per_group <- 30\n\ncommunication_study <- data.frame(\n  participant_id = 1:(3 * n_per_group),\n  communication_method = rep(c(\"email\", \"video_call\", \"face_to_face\"), each = n_per_group),\n  satisfaction_score = c(\n    rnorm(n_per_group, mean = 5.8, sd = 1.3),  # email\n    rnorm(n_per_group, mean = 7.0, sd = 1.3),  # video_call\n    rnorm(n_per_group, mean = 7.5, sd = 1.3)   # face_to_face\n  )\n)\n\n# Save for students\nwrite.csv(communication_study, \"communication_study.csv\", row.names = FALSE)\n\nhead(communication_study)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  participant_id communication_method satisfaction_score\n1              1                email           6.770803\n2              2                email           5.246826\n3              3                email           4.796293\n4              4                email           5.998593\n5              5                email           7.085176\n6              6                email           5.704504\n```\n\n\n:::\n:::\n\n\n## Dataset 5: Exercise Dataset\n\n**Purpose:** Student guided exercise combining regression and t-test\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Generate website A/B test data\nn_per_design <- 50\n\nexercise_data <- data.frame(\n  user_id = 1:(2 * n_per_design),\n  design = rep(c(\"Simple\", \"Complex\"), each = n_per_design),\n  previous_visits = rpois(2 * n_per_design, lambda = 8),\n  time_on_site = c(\n    rnorm(n_per_design, mean = 180, sd = 40),  # Simple\n    rnorm(n_per_design, mean = 240, sd = 50)   # Complex\n  )\n)\n\n# Conversion rate depends on time_on_site and previous_visits\nexercise_data <- exercise_data %>%\n  mutate(\n    conversion_prob = plogis(-2 + 0.01 * time_on_site + 0.05 * previous_visits),\n    converted = rbinom(n(), 1, conversion_prob)\n  )\n\n# Save for students\nwrite.csv(exercise_data, \"exercise_data.csv\", row.names = FALSE)\n\nhead(exercise_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  user_id design previous_visits time_on_site conversion_prob converted\n1       1 Simple              10    179.63774       0.5735567         1\n2       2 Simple              10    121.67466       0.4296563         1\n3       3 Simple               4    207.78119       0.5690097         1\n4       4 Simple               8     81.54658       0.3133435         1\n5       5 Simple               8    185.73159       0.5639764         1\n6       6 Simple               5    164.35112       0.4734029         0\n```\n\n\n:::\n:::\n\n\n---\n\n# Part 1: Introduction & Setup (5 minutes)\n\n## What to Say\n\n> \"Welcome! Today we're focusing on practical implementation of two key analysis methods: linear regression and experimental data analysis. You should have read the tutorials, but don't worry - we'll work through the essential techniques together with hands-on examples.\"\n\n## What to Do\n\n1. **Have students open RStudio**\n2. **Share the data files** (or have them run the generation code)\n3. **Load packages together:**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Students run this\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(broom)\nlibrary(effectsize)\nlibrary(car)\n```\n:::\n\n\n4. **Quick poll:** \"How many of you have the marketing_data loaded successfully?\"\n\n---\n\n# Part 2: Linear Regression (30 minutes)\n\n## 2.1 Simple vs. Multiple Regression (10 min)\n\n### Teaching Notes\n\n**Key Concept:** Show how adding variables changes interpretation from \"total association\" to \"direct effect controlling for other variables\"\n\n**Common Student Misconception:** Students think multiple regression just \"adds more predictors\" - emphasize it changes what each coefficient means!\n\n### Live Coding Script\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# STEP 1: Simple regression\nmodel_simple <- lm(sales_revenue ~ ad_spend, data = marketing_data)\nsummary(model_simple)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = sales_revenue ~ ad_spend, data = marketing_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-38.000 -14.155  -1.484  10.909  48.889 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 67.52803    4.06035   16.63   <2e-16 ***\nad_spend     3.03673    0.06417   47.32   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 17.35 on 98 degrees of freedom\nMultiple R-squared:  0.9581,\tAdjusted R-squared:  0.9576 \nF-statistic:  2239 on 1 and 98 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n**Pause and ask:** \"What does the coefficient for ad_spend mean?\"\n\n**Expected answer:** For every €1 increase in ad spending, sales revenue increases by approximately €{coefficient} on average.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# STEP 2: Multiple regression\nmodel_multiple <- lm(sales_revenue ~ ad_spend + website_traffic, \n                     data = marketing_data)\nsummary(model_multiple)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = sales_revenue ~ ad_spend + website_traffic, data = marketing_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-31.4339  -9.9212  -0.4957   9.7412  31.2228 \n\nCoefficients:\n                Estimate Std. Error t value Pr(>|t|)    \n(Intercept)      15.7527     7.9513   1.981   0.0504 .  \nad_spend          2.1017     0.1407  14.940  < 2e-16 ***\nwebsite_traffic   1.1021     0.1540   7.158 1.58e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 14.11 on 97 degrees of freedom\nMultiple R-squared:  0.9726,\tAdjusted R-squared:  0.972 \nF-statistic:  1719 on 2 and 97 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n**Key teaching moment:** Extract and compare coefficients\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Extract coefficients for comparison\ncoef_simple <- coef(model_simple)[\"ad_spend\"]\ncoef_multiple <- coef(model_multiple)[\"ad_spend\"]\n\ncat(\"Simple model coefficient:\", round(coef_simple, 3), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSimple model coefficient: 3.037 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Multiple model coefficient:\", round(coef_multiple, 3), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMultiple model coefficient: 2.102 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Difference (bias):\", round(coef_simple - coef_multiple, 3), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nDifference (bias): 0.935 \n```\n\n\n:::\n:::\n\n\n### What to Emphasize\n\n> \"Notice how the coefficient for ad_spend **changed** from 3.04 to 2.1. This is because the simple model was **confounding** the effects of ad spending and website traffic. The multiple regression gives us the **direct effect** (ceteris paribus effect) of ad spending, controlling for website traffic.\"\n\n### Omitted Variable Bias - Explain Conceptually\n\n**Draw on board/slides:**\n\n```\nSimple model: Sales ~ Ad_spend\nProblem: Ad_spend → Website_traffic → Sales\n         Ad_spend → Sales\n\nThe simple model attributes BOTH effects to ad_spend!\n\nMultiple model: Sales ~ Ad_spend + Website_traffic\nSolution: Separates direct effect from indirect effect\n```\n\n### Check for Understanding\n\n**Ask class:** \"If we ran a simple regression of Sales on Website Traffic only, would we overestimate or underestimate the effect of traffic?\"\n\n**Answer:** Overestimate - because traffic is correlated with ad spending which also affects sales.\n\n---\n\n## 2.2 Model Diagnostics (8 min)\n\n### Teaching Notes\n\n**Goal:** Show students practical workflow for checking model quality\n**Focus:** R² and basic diagnostic plots\n\n### Live Coding Script\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate R² manually to show what it means\ny_actual <- marketing_data$sales_revenue\ny_fitted <- predict(model_simple)\ny_mean <- mean(y_actual)\n\n# Components\nTSS <- sum((y_actual - y_mean)^2)      # Total Sum of Squares\nRSS <- sum((y_actual - y_fitted)^2)     # Residual Sum of Squares\n\n# R²\nr_squared_manual <- 1 - (RSS / TSS)\nr_squared_r <- summary(model_simple)$r.squared\n\ncat(\"Manual R² calculation:\", round(r_squared_manual, 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nManual R² calculation: 0.9581 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"R's R² calculation:\", round(r_squared_r, 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nR's R² calculation: 0.9581 \n```\n\n\n:::\n:::\n\n\n**Interpretation:**\n\n> \"R² = 0.96 means our model explains 95.8% of the variation in sales revenue. The remaining 4.2% is unexplained.\"\n\n### Diagnostic Plots\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create augmented data\nmodel_data <- augment(model_multiple)\n\n# Two key plots\nlibrary(gridExtra)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'gridExtra'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following object is masked from 'package:dplyr':\n\n    combine\n```\n\n\n:::\n\n```{.r .cell-code}\np1 <- ggplot(model_data, aes(x = .fitted, y = .resid)) +\n  geom_point(alpha = 0.6) +\n  geom_hline(yintercept = 0, linetype = \"dashed\", color = \"red\") +\n  geom_smooth(se = FALSE, color = \"blue\") +\n  labs(title = \"Residuals vs Fitted\",\n       subtitle = \"Should show random scatter (no pattern)\",\n       x = \"Fitted Values\", \n       y = \"Residuals\") +\n  theme_minimal()\n\np2 <- ggplot(model_data, aes(sample = .resid)) +\n  stat_qq() +\n  stat_qq_line(color = \"red\") +\n  labs(title = \"Normal Q-Q Plot\",\n       subtitle = \"Points should follow red line\",\n       x = \"Theoretical Quantiles\",\n       y = \"Sample Quantiles\") +\n  theme_minimal()\n\ngrid.arrange(p1, p2, ncol = 2)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](lab_session_guide_files/figure-html/diagnostic-plots-1.png){width=960}\n:::\n:::\n\n\n### What to Say\n\n> \"These diagnostic plots help us check our model assumptions:\n> \n> - **Left plot:** Residuals vs Fitted - we want random scatter with no clear pattern. A pattern would suggest we're missing something in our model.\n> - **Right plot:** Q-Q plot - points should follow the red line, indicating residuals are normally distributed.\"\n\n**Quick check:** \"Do these plots look okay?\" (Yes, they do)\n\n---\n\n## 2.3 Log Transformation (12 min)\n\n### Teaching Notes\n\n**Why this matters:** Real business data often shows exponential growth (revenue over time, user growth, compound returns)\n\n**Key insight:** Log transformation linearizes exponential relationships\n\n### Setup the Problem\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Visualize the exponential relationship\nggplot(firm_growth_data, aes(x = year, y = revenue)) +\n  geom_point(size = 3, alpha = 0.8) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\", linewidth = 1) +\n  geom_smooth(method = \"loess\", se = FALSE, color = \"blue\", linewidth = 1) +\n  labs(title = \"Company Revenue Growth Over Time\",\n       subtitle = \"Red = Linear fit (inadequate), Blue = Flexible fit\",\n       x = \"Year\",\n       y = \"Revenue (EUR)\") +\n  scale_y_continuous(labels = scales::comma) +\n  theme_minimal()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](lab_session_guide_files/figure-html/exponential-problem-1.png){width=768}\n:::\n:::\n\n\n**Point out:** \"The red linear line completely fails to capture the exponential pattern!\"\n\n### Apply Log Transformation\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create log-transformed variable\nfirm_growth_data <- firm_growth_data %>%\n  mutate(log_revenue = log(revenue))\n\n# Fit both models\nmodel_linear <- lm(revenue ~ year, data = firm_growth_data)\nmodel_log <- lm(log_revenue ~ year, data = firm_growth_data)\n\n# Compare R²\nr2_linear <- summary(model_linear)$r.squared\nr2_log <- summary(model_log)$r.squared\n\ncat(\"Linear model R²:\", round(r2_linear, 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLinear model R²: 0.9188 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Log model R²:\", round(r2_log, 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLog model R²: 0.9583 \n```\n\n\n:::\n:::\n\n\n### Visualize the Transformation\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Plot log-transformed data\nggplot(firm_growth_data, aes(x = year, y = log_revenue)) +\n  geom_point(size = 3, alpha = 0.8) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"blue\", linewidth = 1) +\n  labs(title = \"Log(Revenue) vs Year\",\n       subtitle = \"Perfect linear relationship after transformation!\",\n       x = \"Year\",\n       y = \"Log(Revenue)\") +\n  theme_minimal()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](lab_session_guide_files/figure-html/log-visualization-1.png){width=768}\n:::\n:::\n\n\n**What to emphasize:**\n\n> \"After log transformation, the relationship becomes perfectly linear! The R² jumped from 0.92 to 0.96.\"\n\n### Interpretation of Log-Transformed Models\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Get coefficient for year\ncoef_log <- coef(model_log)[\"year\"]\npercentage_change <- (exp(coef_log) - 1) * 100\n\ncat(\"Coefficient in log model:\", round(coef_log, 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCoefficient in log model: 0.1304 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"This means:\", round(percentage_change, 2), \"% growth per year\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nThis means: 13.93 % growth per year\n```\n\n\n:::\n:::\n\n\n**Key point for interpretation:**\n\n> \"When we log-transform the dependent variable, coefficients represent **percentage changes**. Each year is associated with approximately 13.9% growth in revenue.\"\n\n### Visual Proof: Back to Original Scale\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create predictions on original scale\npredictions <- firm_growth_data %>%\n  mutate(\n    linear_pred = predict(model_linear),\n    log_pred = exp(predict(model_log))  # Back-transform!\n  )\n\nggplot(predictions, aes(x = year)) +\n  geom_point(aes(y = revenue), size = 3, alpha = 0.8) +\n  geom_line(aes(y = linear_pred), color = \"red\", linewidth = 1.2) +\n  geom_line(aes(y = log_pred), color = \"blue\", linewidth = 1.2) +\n  labs(title = \"Model Predictions Comparison\",\n       subtitle = \"Red = Linear model (poor fit), Blue = Log model (excellent fit)\",\n       x = \"Year\",\n       y = \"Revenue (EUR)\") +\n  scale_y_continuous(labels = scales::comma) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](lab_session_guide_files/figure-html/back-transform-1.png){width=768}\n:::\n:::\n\n\n**Final message:**\n\n> \"The log model (blue) captures the exponential growth pattern perfectly, while the linear model (red) systematically misses the pattern. This is why data transformation is so important!\"\n\n---\n\n# Part 3: Experimental Analysis (35 minutes)\n\n## 3.1 t-Tests (15 min)\n\n### Teaching Notes\n\n**Research Question:** Does leadership training improve team performance?\n\n**Key workflow:** \n1. Explore data visually\n2. Check assumptions\n3. Run test\n4. Calculate effect size\n5. Interpret for business decisions\n\n### Visual Exploration\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(leadership_study_between, aes(x = group, y = team_performance, fill = group)) +\n  geom_boxplot(alpha = 0.7) +\n  geom_jitter(width = 0.2, alpha = 0.5) +\n  stat_summary(fun = mean, geom = \"point\", shape = 23, size = 3, fill = \"red\") +\n  labs(title = \"Team Performance by Group\",\n       subtitle = \"Red diamonds show group means\",\n       x = \"Group\",\n       y = \"Team Performance Score\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n```\n\n::: {.cell-output-display}\n![](lab_session_guide_files/figure-html/leadership-visualization-1.png){width=768}\n:::\n:::\n\n\n**Ask class:** \"Based on this plot, do you think there's a difference?\"\n\n### Check Assumptions\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Normality test for each group\nshapiro_control <- shapiro.test(\n  filter(leadership_study_between, group == \"control\")$team_performance\n)\nshapiro_training <- shapiro.test(\n  filter(leadership_study_between, group == \"training\")$team_performance\n)\n\ncat(\"Shapiro-Wilk test for control group: p =\", \n    round(shapiro_control$p.value, 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nShapiro-Wilk test for control group: p = 0.9312 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Shapiro-Wilk test for training group: p =\", \n    round(shapiro_training$p.value, 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nShapiro-Wilk test for training group: p = 0.4427 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Equal variances test\nlevene_result <- leveneTest(team_performance ~ group, \n                            data = leadership_study_between)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in leveneTest.default(y = y, group = group, ...): group coerced to\nfactor.\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"\\nLevene's test for equal variances: p =\", \n    round(levene_result$`Pr(>F)`[1], 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nLevene's test for equal variances: p = 0.1078 \n```\n\n\n:::\n:::\n\n\n**Interpretation:**\n\n> \"Both p-values are > 0.05, so we cannot reject the hypotheses of normality and equal variances. We can proceed with the standard t-test.\"\n\n### Run t-test\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt_result <- t.test(\n  team_performance ~ group,\n  data = leadership_study_between,\n  var.equal = TRUE\n)\n\nprint(t_result)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tTwo Sample t-test\n\ndata:  team_performance by group\nt = -3.7092, df = 58, p-value = 0.0004673\nalternative hypothesis: true difference in means between group control and group training is not equal to 0\n95 percent confidence interval:\n -12.154597  -3.634084\nsample estimates:\n mean in group control mean in group training \n              75.92457               83.81891 \n```\n\n\n:::\n:::\n\n\n**Interpretation guide:**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean_diff <- diff(t_result$estimate)\np_value <- t_result$p.value\nci_lower <- t_result$conf.int[1]\nci_upper <- t_result$conf.int[2]\n\ncat(\"Mean difference:\", round(mean_diff, 2), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMean difference: 7.89 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"95% CI: [\", round(ci_lower, 2), \",\", round(ci_upper, 2), \"]\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n95% CI: [ -12.15 , -3.63 ]\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"p-value:\", format.pval(p_value, digits = 3), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\np-value: 0.000467 \n```\n\n\n:::\n:::\n\n\n> \"The training group scored 7.9 points higher on average. With p < 0.001, this difference is highly statistically significant.\"\n\n### Effect Size\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncohens_d_result <- cohens_d(team_performance ~ group, \n                            data = leadership_study_between)\nprint(cohens_d_result)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCohen's d |         95% CI\n--------------------------\n-0.96     | [-1.49, -0.42]\n\n- Estimated using pooled SD.\n```\n\n\n:::\n:::\n\n\n**Interpretation:**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_value <- abs(cohens_d_result$Cohens_d)\n\neffect_label <- ifelse(d_value < 0.5, \"small\",\n                      ifelse(d_value < 0.8, \"medium\", \"large\"))\n\ncat(\"Cohen's d =\", round(d_value, 2), \"(\", effect_label, \"effect)\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCohen's d = 0.96 ( large effect)\n```\n\n\n:::\n:::\n\n\n> \"Cohen's d = 0.96 indicates a **large effect**. This means the difference is not only statistically significant but also **practically meaningful** for business decisions.\"\n\n**Business decision:**\n\n> \"Based on these results, the leadership training shows a large, significant improvement in team performance. If the training costs less than the value of a 7.9-point performance improvement, it's worth implementing.\"\n\n---\n\n## 3.2 One-Way ANOVA (12 min)\n\n### Teaching Notes\n\n**Research Question:** Which communication method leads to highest satisfaction?\n\n**Key concept:** ANOVA tests whether at least one group differs from others (not which specific groups differ - that requires post-hoc tests)\n\n### Visual Exploration\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate means for plotting\ncomm_means <- communication_study %>%\n  group_by(communication_method) %>%\n  summarise(\n    mean_satisfaction = mean(satisfaction_score),\n    se = sd(satisfaction_score) / sqrt(n())\n  )\n\nggplot(communication_study, aes(x = communication_method, y = satisfaction_score)) +\n  geom_jitter(width = 0.2, alpha = 0.4, color = \"gray40\") +\n  geom_point(data = comm_means, aes(y = mean_satisfaction), \n             size = 4, color = \"red\") +\n  geom_errorbar(data = comm_means, \n                aes(y = mean_satisfaction, \n                    ymin = mean_satisfaction - 1.96*se,\n                    ymax = mean_satisfaction + 1.96*se),\n                width = 0.2, color = \"red\", linewidth = 1) +\n  labs(title = \"Satisfaction Score by Communication Method\",\n       subtitle = \"Red points = means with 95% confidence intervals\",\n       x = \"Communication Method\",\n       y = \"Satisfaction Score\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](lab_session_guide_files/figure-html/anova-visualization-1.png){width=768}\n:::\n:::\n\n\n### Fit ANOVA\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fit model\nanova_model <- aov(satisfaction_score ~ communication_method, \n                   data = communication_study)\nsummary(anova_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                     Df Sum Sq Mean Sq F value   Pr(>F)    \ncommunication_method  2  51.46  25.731   16.37 9.21e-07 ***\nResiduals            87 136.72   1.571                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n**Interpretation:**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanova_summary <- summary(anova_model)\nf_value <- anova_summary[[1]]$`F value`[1]\np_value_anova <- anova_summary[[1]]$`Pr(>F)`[1]\n\ncat(\"F-statistic =\", round(f_value, 2), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nF-statistic = 16.37 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"p-value:\", format.pval(p_value_anova, digits = 3), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\np-value: 9.21e-07 \n```\n\n\n:::\n:::\n\n\n> \"The very small p-value (p < 0.001) tells us that **at least one** communication method produces significantly different satisfaction scores than the others. But it doesn't tell us *which* methods differ.\"\n\n### Connection to Regression\n\n**Key teaching point:**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Show that lm() gives identical results\nlm_model <- lm(satisfaction_score ~ communication_method, \n               data = communication_study)\nanova(lm_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Variance Table\n\nResponse: satisfaction_score\n                     Df  Sum Sq Mean Sq F value    Pr(>F)    \ncommunication_method  2  51.462 25.7312  16.374 9.212e-07 ***\nResiduals            87 136.716  1.5714                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n> \"ANOVA is just a special case of regression! When we use categorical predictors, R creates dummy variables automatically.\"\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(lm_model)$coefficients\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                                 Estimate Std. Error   t value     Pr(>|t|)\n(Intercept)                      5.656295  0.2288701 24.713991 4.231093e-41\ncommunication_methodface_to_face 1.641875  0.3236713  5.072663 2.195718e-06\ncommunication_methodvideo_call   1.563436  0.3236713  4.830320 5.797655e-06\n```\n\n\n:::\n:::\n\n\n**Explain:**\n\n> \"Since 'email' comes first alphabetically, it's the reference group. The coefficients show:\n>\n> - Intercept = mean satisfaction for email group\n> - face_to_face coefficient = difference between face_to_face and email\n> - video_call coefficient = difference between video_call and email\"\n\n### Effect Size\n\n\n::: {.cell}\n\n```{.r .cell-code}\neta_sq <- eta_squared(anova_model)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nFor one-way between subjects designs, partial eta squared is equivalent\n  to eta squared. Returning eta squared.\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(eta_sq)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Effect Size for ANOVA\n\nParameter            | Eta2 |       95% CI\n------------------------------------------\ncommunication_method | 0.27 | [0.14, 1.00]\n\n- One-sided CIs: upper bound fixed at [1.00].\n```\n\n\n:::\n:::\n\n\n**Interpretation:**\n\n\n::: {.cell}\n\n```{.r .cell-code}\neta_value <- eta_sq$Eta2[1]\ncat(\"η² =\", round(eta_value, 3), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nη² = 0.273 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Communication method explains\", round(eta_value * 100, 1), \n    \"% of variance in satisfaction\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCommunication method explains 27.3 % of variance in satisfaction\n```\n\n\n:::\n:::\n\n\n### Post-Hoc Tests\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntukey_result <- TukeyHSD(anova_model)\nprint(tukey_result)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = satisfaction_score ~ communication_method, data = communication_study)\n\n$communication_method\n                               diff        lwr       upr     p adj\nface_to_face-email       1.64187523  0.8700877 2.4136627 0.0000065\nvideo_call-email         1.56343582  0.7916483 2.3352233 0.0000172\nvideo_call-face_to_face -0.07843941 -0.8502269 0.6933481 0.9681547\n```\n\n\n:::\n:::\n\n\n**Create visualization:**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Convert to data frame for plotting\ntukey_df <- as.data.frame(tukey_result$communication_method)\ntukey_df$comparison <- rownames(tukey_df)\n\nggplot(tukey_df, aes(x = comparison, y = diff)) +\n  geom_point(size = 3) +\n  geom_errorbar(aes(ymin = lwr, ymax = upr), width = 0.2) +\n  geom_hline(yintercept = 0, linetype = \"dashed\", color = \"red\") +\n  coord_flip() +\n  labs(title = \"Pairwise Comparisons (Tukey HSD)\",\n       subtitle = \"Significant if confidence interval doesn't include zero\",\n       x = \"Comparison\",\n       y = \"Mean Difference\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](lab_session_guide_files/figure-html/tukey-plot-1.png){width=768}\n:::\n:::\n\n\n**Interpretation:**\n\n> \"The post-hoc tests reveal:\n>\n> - Face-to-face vs email: Significant difference (CI doesn't include 0)\n> - Video_call vs email: Significant difference\n> - Video_call vs face_to_face: NOT significant (CI includes 0)\n>\n> **Conclusion:** Both face-to-face and video calls produce higher satisfaction than email, but face-to-face and video don't differ significantly from each other.\"\n\n---\n\n## 3.3 Brief Preview: Factorial Designs (8 min)\n\n### Teaching Notes\n\n**Note:** Students haven't learned about interactions formally in the tutorials. Keep this light and conceptual.\n\n**Goal:** Plant the seed that effects can depend on other variables\n\n### Conceptual Introduction\n\n> \"So far we've looked at one factor at a time. But what if the effect of one variable **depends on** another variable? That's what factorial designs let us explore.\"\n\n### Simple Example (Conceptual)\n\n**On board/slide:**\n\n```\nResearch Question: Does feedback type (positive vs. critical) \naffect performance improvement?\n\nBut wait... does this depend on experience level?\n\nMaybe:\n- Novices benefit from positive feedback (encouragement)\n- Experts benefit from critical feedback (growth mindset)\n\nThis is called an INTERACTION EFFECT.\n```\n\n### Show the Pattern Visually\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](lab_session_guide_files/figure-html/interaction-concept-1.png){width=672}\n:::\n:::\n\n\n**Point out:**\n\n> \"Notice how the lines cross? This tells us the effect of feedback type is **different** for novices vs. experts. That's an interaction!\n>\n> - For novices: Positive feedback works better\n> - For experts: Critical feedback works better\n>\n> If there was no interaction, the lines would be parallel.\"\n\n### Why This Matters\n\n> \"Interactions are everywhere in business:\n>\n> - Does advertising effectiveness depend on customer segment?\n> - Does training effectiveness depend on prior knowledge?\n> - Does pricing strategy depend on market conditions?\n>\n> The tutorials cover how to test for interactions with two-way ANOVA. For now, just remember: **effects can depend on context**.\"\n\n**Transition to exercise:**\n\n> \"In your exercise, you'll work with simpler designs - just regression and t-tests. But keep interactions in mind for future analyses!\"\n\n---\n\n# Part 4: Guided Exercise (20 minutes)\n\n## Exercise Setup (2 min)\n\n### Scenario\n\nYou have data from an A/B test of two website designs:\n\n- **Simple Design:** Minimalist layout, fewer options\n- **Complex Design:** Feature-rich layout, many options\n\n**Variables measured:**\n\n- `design`: Which design the user saw (Simple vs. Complex)\n- `time_on_site`: Time spent on site (seconds)\n- `previous_visits`: Number of previous visits to the site\n- `converted`: Whether user made a purchase (1 = yes, 0 = no)\n\n**Dataset:** `exercise_data.csv`\n\n### Tasks for Students\n\n**Task 1: Regression Analysis**\n\na. Create a scatter plot of `time_on_site` vs `converted`\nb. Fit a linear regression: `converted ~ time_on_site`\nc. Interpret the coefficient for `time_on_site`\nd. Calculate and report R²\n\n**Task 2: Compare Designs**\n\na. Use a t-test to compare `time_on_site` between the two designs\nb. Calculate Cohen's d effect size\nc. Which design keeps users on the site longer?\n\n**Task 3: Omitted Variable Bias (Challenge)**\n\na. Add `previous_visits` to your regression model\nb. How does the coefficient for `time_on_site` change?\nc. Does this suggest omitted variable bias? Why or why not?\n\n---\n\n## Solution Guide (For Discussion)\n\n### Task 1 Solution\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load data\nexercise_data <- read.csv(\"exercise_data.csv\")\n\n# a. Scatter plot\nggplot(exercise_data, aes(x = time_on_site, y = converted)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(method = \"lm\", se = TRUE) +\n  labs(title = \"Conversion vs Time on Site\",\n       x = \"Time on Site (seconds)\",\n       y = \"Converted (0/1)\") +\n  theme_minimal()\n\n# b. Simple regression\nmodel_exercise_simple <- lm(converted ~ time_on_site, data = exercise_data)\nsummary(model_exercise_simple)\n\n# c. Interpretation\ncoef_time <- coef(model_exercise_simple)[\"time_on_site\"]\ncat(\"For every additional second on site, conversion probability increases by\",\n    round(coef_time, 4), \"\\n\")\n\n# d. R²\nr2 <- summary(model_exercise_simple)$r.squared\ncat(\"R² =\", round(r2, 4), \"meaning the model explains\", \n    round(r2*100, 1), \"% of variance\\n\")\n```\n:::\n\n\n### Task 2 Solution\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# a. t-test\nt_test_design <- t.test(time_on_site ~ design, data = exercise_data)\nprint(t_test_design)\n\n# b. Effect size\ncohens_d_design <- cohens_d(time_on_site ~ design, data = exercise_data)\nprint(cohens_d_design)\n\n# c. Interpretation\ncat(\"Complex design keeps users\", abs(round(diff(t_test_design$estimate), 1)),\n    \"seconds longer on average\\n\")\n```\n:::\n\n\n### Task 3 Solution\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# a. Add previous_visits\nmodel_exercise_multiple <- lm(converted ~ time_on_site + previous_visits, \n                              data = exercise_data)\nsummary(model_exercise_multiple)\n\n# b. Compare coefficients\ncoef_simple <- coef(model_exercise_simple)[\"time_on_site\"]\ncoef_multiple <- coef(model_exercise_multiple)[\"time_on_site\"]\n\ncat(\"Simple model coefficient:\", round(coef_simple, 5), \"\\n\")\ncat(\"Multiple model coefficient:\", round(coef_multiple, 5), \"\\n\")\ncat(\"Change:\", round(coef_multiple - coef_simple, 5), \"\\n\")\n\n# c. Interpretation\n# If coefficient changed substantially, there was omitted variable bias\n# This happens when previous_visits correlates with both time_on_site \n# and converted\n```\n:::\n\n\n---\n\n## Discussion Points (3 min)\n\n**Call on students to share:**\n\n1. \"What did you find in Task 1? Is time on site a good predictor?\"\n2. \"In Task 2, which design won? Was the effect large?\"\n3. \"In Task 3, did the coefficient change much? What does that tell us?\"\n\n**Key takeaways to emphasize:**\n\n- Time on site predicts conversion, but R² might be modest\n- One design likely keeps users longer (check which one!)\n- If previous_visits affected the coefficient, it was a confounder\n- This is why we need multiple regression - to control for confounders!\n\n---\n\n# Part 5: Wrap-up (5 minutes)\n\n## Key Concepts Review\n\n### Linear Regression\n\n✅ **Multiple regression** controls for confounders and gives *ceteris paribus* effects  \n✅ **Omitted variable bias** happens when we leave out relevant variables  \n✅ **Log transformation** linearizes exponential relationships  \n✅ **R²** measures explained variance, but doesn't tell the whole story  \n✅ **Diagnostic plots** check model assumptions\n\n### Experimental Analysis\n\n✅ **Always check assumptions** before running tests  \n✅ **t-tests** compare two groups  \n✅ **ANOVA** compares three or more groups  \n✅ **Effect sizes** (Cohen's d, η²) tell us about practical significance  \n✅ **Post-hoc tests** identify which specific groups differ  \n✅ **ANOVA is regression** with categorical predictors\n\n## Resources\n\n- **Tutorials:** Full details on all methods we covered today\n- **Power analysis:** See experiments tutorial for sample size planning\n- **Office hours:** For questions on your own data/projects\n\n## Final Message\n\n> \"Statistics is not just about getting significant p-values. It's about:\n> \n> 1. Understanding what your data can and cannot tell you\n> 2. Making valid comparisons by controlling for confounders\n> 3. Assessing practical significance, not just statistical significance\n> 4. Checking assumptions so your results are trustworthy\n>\n> Practice these workflows, and you'll be able to analyze real data effectively!\"\n\n---\n\n# Appendix: Common Student Questions\n\n## \"When should I use log transformation?\"\n\n- When you see exponential growth/decay patterns\n- When plotting shows a curve that gets steeper over time\n- When residuals show a pattern (heteroscedasticity)\n- Common in: revenue over time, population growth, compound effects\n\n## \"What if my assumptions are violated?\"\n\n- **Non-normal data:** Use non-parametric tests (Wilcoxon, Kruskal-Wallis)\n- **Unequal variances:** Use Welch's t-test or robust ANOVA\n- **Small samples:** Bootstrap methods\n- **Always visualize first** - sometimes transformations help!\n\n## \"How do I know if an effect size is 'big enough'?\"\n\n- Cohen's guidelines are just rules of thumb\n- Consider the **context**:\n  - A 2% improvement in click-through rate might be huge for online advertising\n  - A 10-point IQ difference might be small for educational interventions\n- Ask: \"Is this large enough to matter for decisions?\"\n\n## \"Simple vs. multiple regression - which should I use?\"\n\n- **Simple:** When you have one clear predictor and no obvious confounders\n- **Multiple:** Almost always in real research!\n  - Controls for confounders\n  - More accurate effect estimates\n  - Allows you to compare importance of different predictors\n\n## \"What's the difference between aov() and lm()?\"\n\n- They're the same! ANOVA is regression with categorical predictors\n- Use `aov()` for traditional ANOVA output\n- Use `lm()` when you want to see coefficients or add continuous predictors\n- Both give identical F-statistics and p-values\n",
    "supporting": [
      "lab_session_guide_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}